{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Homework\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "columns_without_price = columns.copy()\n",
    "columns_without_price.remove('price')\n",
    "df = pd.read_csv('data.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group               0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "room_type                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.log1p(df.price.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.price.values\n",
    "del df_train['price']\n",
    "\n",
    "y_val = df_val.price.values\n",
    "del df_val['price']\n",
    "\n",
    "y_test = df_test.price.values\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[columns_without_price].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[columns_without_price].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    " \n",
    "model = DecisionTreeRegressor(max_depth = 1)\n",
    "model.fit(X_train, y_train)\n",
    "feature = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- room_type=Entire home/apt <= 0.50\n",
      "|   |--- value: [4.29]\n",
      "|--- room_type=Entire home/apt >  0.50\n",
      "|   |--- value: [5.15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(model, feature_names = feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4615632303514057"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred)** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For estimators 10, RMSE is 0.462\n",
      "For estimators 20, RMSE is 0.448\n",
      "For estimators 30, RMSE is 0.446\n",
      "For estimators 40, RMSE is 0.444\n",
      "For estimators 50, RMSE is 0.442\n",
      "For estimators 60, RMSE is 0.442\n",
      "For estimators 70, RMSE is 0.441\n",
      "For estimators 80, RMSE is 0.441\n",
      "For estimators 90, RMSE is 0.441\n",
      "For estimators 100, RMSE is 0.440\n",
      "For estimators 110, RMSE is 0.439\n",
      "For estimators 120, RMSE is 0.439\n",
      "For estimators 130, RMSE is 0.439\n",
      "For estimators 140, RMSE is 0.439\n",
      "For estimators 150, RMSE is 0.439\n",
      "For estimators 160, RMSE is 0.439\n",
      "For estimators 170, RMSE is 0.439\n",
      "For estimators 180, RMSE is 0.439\n",
      "For estimators 190, RMSE is 0.439\n",
      "For estimators 200, RMSE is 0.439\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 201, 10):\n",
    "    model = RandomForestRegressor(n_estimators = i, random_state=1, n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred) ** 0.5 \n",
    "    print(\"For estimators %s, RMSE is %.3f\" % (i, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth 10 \n",
      "\n",
      "For estimators 10, RMSE is 0.446\n",
      "For estimators 20, RMSE is 0.442\n",
      "For estimators 30, RMSE is 0.441\n",
      "For estimators 40, RMSE is 0.441\n",
      "For estimators 50, RMSE is 0.441\n",
      "For estimators 60, RMSE is 0.441\n",
      "For estimators 70, RMSE is 0.441\n",
      "For estimators 80, RMSE is 0.441\n",
      "For estimators 90, RMSE is 0.440\n",
      "For estimators 100, RMSE is 0.440\n",
      "For estimators 110, RMSE is 0.440\n",
      "For estimators 120, RMSE is 0.440\n",
      "For estimators 130, RMSE is 0.440\n",
      "For estimators 140, RMSE is 0.440\n",
      "For estimators 150, RMSE is 0.440\n",
      "For estimators 160, RMSE is 0.440\n",
      "For estimators 170, RMSE is 0.440\n",
      "For estimators 180, RMSE is 0.440\n",
      "For estimators 190, RMSE is 0.440\n",
      "For estimators 200, RMSE is 0.440\n",
      "For max_depth 15 \n",
      "\n",
      "For estimators 10, RMSE is 0.450\n",
      "For estimators 20, RMSE is 0.441\n",
      "For estimators 30, RMSE is 0.440\n",
      "For estimators 40, RMSE is 0.439\n",
      "For estimators 50, RMSE is 0.438\n",
      "For estimators 60, RMSE is 0.438\n",
      "For estimators 70, RMSE is 0.437\n",
      "For estimators 80, RMSE is 0.437\n",
      "For estimators 90, RMSE is 0.437\n",
      "For estimators 100, RMSE is 0.437\n",
      "For estimators 110, RMSE is 0.436\n",
      "For estimators 120, RMSE is 0.436\n",
      "For estimators 130, RMSE is 0.436\n",
      "For estimators 140, RMSE is 0.436\n",
      "For estimators 150, RMSE is 0.436\n",
      "For estimators 160, RMSE is 0.436\n",
      "For estimators 170, RMSE is 0.436\n",
      "For estimators 180, RMSE is 0.436\n",
      "For estimators 190, RMSE is 0.436\n",
      "For estimators 200, RMSE is 0.436\n",
      "For max_depth 20 \n",
      "\n",
      "For estimators 10, RMSE is 0.458\n",
      "For estimators 20, RMSE is 0.446\n",
      "For estimators 30, RMSE is 0.443\n",
      "For estimators 40, RMSE is 0.442\n",
      "For estimators 50, RMSE is 0.441\n",
      "For estimators 60, RMSE is 0.440\n",
      "For estimators 70, RMSE is 0.440\n",
      "For estimators 80, RMSE is 0.440\n",
      "For estimators 90, RMSE is 0.439\n",
      "For estimators 100, RMSE is 0.439\n",
      "For estimators 110, RMSE is 0.438\n",
      "For estimators 120, RMSE is 0.438\n",
      "For estimators 130, RMSE is 0.438\n",
      "For estimators 140, RMSE is 0.438\n",
      "For estimators 150, RMSE is 0.438\n",
      "For estimators 160, RMSE is 0.438\n",
      "For estimators 170, RMSE is 0.438\n",
      "For estimators 180, RMSE is 0.438\n",
      "For estimators 190, RMSE is 0.438\n",
      "For estimators 200, RMSE is 0.438\n",
      "For max_depth 25 \n",
      "\n",
      "For estimators 10, RMSE is 0.461\n",
      "For estimators 20, RMSE is 0.447\n",
      "For estimators 30, RMSE is 0.445\n",
      "For estimators 40, RMSE is 0.443\n",
      "For estimators 50, RMSE is 0.442\n",
      "For estimators 60, RMSE is 0.442\n",
      "For estimators 70, RMSE is 0.441\n",
      "For estimators 80, RMSE is 0.441\n",
      "For estimators 90, RMSE is 0.440\n",
      "For estimators 100, RMSE is 0.440\n",
      "For estimators 110, RMSE is 0.439\n",
      "For estimators 120, RMSE is 0.439\n",
      "For estimators 130, RMSE is 0.439\n",
      "For estimators 140, RMSE is 0.439\n",
      "For estimators 150, RMSE is 0.439\n",
      "For estimators 160, RMSE is 0.439\n",
      "For estimators 170, RMSE is 0.439\n",
      "For estimators 180, RMSE is 0.439\n",
      "For estimators 190, RMSE is 0.439\n",
      "For estimators 200, RMSE is 0.439\n"
     ]
    }
   ],
   "source": [
    "for depth in [10,15,20,25]:\n",
    "    print('For max_depth %s \\n' % depth)\n",
    "    for i in range(10, 201, 10):\n",
    "        model = RandomForestRegressor(n_estimators = i, random_state=1, n_jobs = -1, max_depth = depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred) ** 0.5 \n",
    "        print(\"For estimators %s, RMSE is %.3f\" % (i, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43869448497893626\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_estimators = 10, random_state=1, n_jobs = -1, max_depth= 20)\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred) ** 0.5 \n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4386944849789362\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_estimators = 10, random_state=5, n_jobs = -1, max_depth= 20)\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred) ** 0.5 \n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 10, max_depth = 20, random_state=1, n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'feature': dv.get_feature_names(), 'values': model.feature_importances_}\n",
    "feature_info_values = pd.DataFrame(data = d)\n",
    "feature_info_values.sort_values('values', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Work\\ml_course\\ml_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = dv.get_feature_names()\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train, feature_names = features)\n",
    "dval = xgb.DMatrix(X_val, label = y_val, feature_names = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43621034591295677\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round = 100)\n",
    "y_pred = model.predict(dval)\n",
    "rmse = mean_squared_error(y_pred,y_val) ** 0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43249655247991464\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round = 100)\n",
    "y_pred = model.predict(dval)\n",
    "rmse = mean_squared_error(y_pred,y_val) ** 0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.630452438951798\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round = 100)\n",
    "y_pred = model.predict(dval)\n",
    "rmse = mean_squared_error(y_pred,y_val) ** 0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "ml_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
